{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeCy5qjpdaJ41xfP7AtHjW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DSGP-Group-1-EAPS/BackupDataset/blob/main/Artificial_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjqV71U8Jhu1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Read the CSV file\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/DSGP_COURSEWORK/Absenteeism_at_work_Project.csv')\n",
        "\n",
        "# Clean the \"Work load Average/day\" column by removing commas and converting to numeric\n",
        "df[\"Work load Average/day \"] = df[\"Work load Average/day \"].str.replace(',', '').astype(float)\n",
        "\n",
        "# Replace missing values with the mean of each column\n",
        "df.fillna(df.mean().round(0), inplace=True)\n",
        "\n",
        "# Separate features and target variable\n",
        "x = df.iloc[:, :19].to_numpy()\n",
        "y = df[\"Absenteeism time in hours\"].to_numpy()\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features (optional, but often recommended for neural networks)\n",
        "scaler = StandardScaler()\n",
        "xtrain = scaler.fit_transform(xtrain)\n",
        "xtest = scaler.transform(xtest)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(64, activation='relu', input_shape=(xtrain.shape[1],)))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "# Train the model\n",
        "model.fit(xtrain, ytrain, epochs=50, batch_size=32, validation_data=(xtest, ytest), verbose=2)\n",
        "\n",
        "# Make predictions\n",
        "ytrain_pred = model.predict(xtrain)\n",
        "ytest_pred = model.predict(xtest)\n",
        "\n",
        "# Evaluate the model\n",
        "train_r2 = r2_score(ytrain, ytrain_pred)\n",
        "test_r2 = r2_score(ytest, ytest_pred)\n",
        "print(x)\n",
        "print(y)\n",
        "print(f\"Train R-squared: {train_r2}\")\n",
        "print(f\"Test R-squared: {test_r2}\")\n"
      ]
    }
  ]
}